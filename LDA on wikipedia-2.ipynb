{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample LDA ON csv data instead of xml. In reality most probably we will be using xml data by wikipedia.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.read_csv('abcnews-date-text.csv',error_bad_lines=False);\n",
    "data=pd.read_csv('abcnews-date-text.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data[['headline_text']]))\n",
    "print(type(data['headline_text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text=data[['headline_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             headline_text    index\n",
      "0        aba decides against community broadcasting lic...        0\n",
      "1           act fire witnesses must be aware of defamation        1\n",
      "2           a g calls for infrastructure protection summit        2\n",
      "3                 air nz staff in aust strike for pay rise        3\n",
      "4            air nz strike to affect australian travellers        4\n",
      "5                        ambitious olsson wins triple jump        5\n",
      "6               antic delighted with record breaking barca        6\n",
      "7        aussie qualifier stosur wastes four memphis match        7\n",
      "8             aust addresses un security council over iraq        8\n",
      "9               australia is locked into war timetable opp        9\n",
      "10       australia to contribute 10 million in aid to iraq       10\n",
      "11       barca take record as robson celebrates birthda...       11\n",
      "12                              bathhouse plans move ahead       12\n",
      "13           big hopes for launceston cycling championship       13\n",
      "14                  big plan to boost paroo water supplies       14\n",
      "15                  blizzard buries united states in bills       15\n",
      "16          brigadier dismisses reports troops harassed in       16\n",
      "17          british combat troops arriving daily in kuwait       17\n",
      "18              bryant leads lakers to double overtime win       18\n",
      "19                bushfire victims urged to see centrelink       19\n",
      "20         businesses should prepare for terrorist attacks       20\n",
      "21         calleri avenges final defeat to eliminate massu       21\n",
      "22                 call for ethanol blend fuel to go ahead       22\n",
      "23                  carews freak goal leaves roma in ruins       23\n",
      "24                            cemeteries miss out on funds       24\n",
      "25       code of conduct toughens organ donation regula...       25\n",
      "26            commonwealth bank cuts fixed home loan rates       26\n",
      "27                  community urged to help homeless youth       27\n",
      "28        council chief executive fails to secure position       28\n",
      "29         councillor to contest wollongong as independent       29\n",
      "...                                                    ...      ...\n",
      "1103633        nepal bans solo climbers from mount everest  1103633\n",
      "1103634     new years eve 2018 celebrated around australia  1103634\n",
      "1103635  new years eve australia prepares to bring in 2018  1103635\n",
      "1103636        new years eve celebrations around the world  1103636\n",
      "1103637  new years texting data load to surge as clock ...  1103637\n",
      "1103638     north korea leader kim jong un watches concert  1103638\n",
      "1103639   now its real tourists converge on sydney harbour  1103639\n",
      "1103640  nye guide for sydney best venues public transp...  1103640\n",
      "1103641    police confirm deaths of six people in seaplane  1103641\n",
      "1103642  police officer brett forte; killed in a shooti...  1103642\n",
      "1103643     p plate driver caught 100 kph over speed limit  1103643\n",
      "1103644         protesters throw rocks at police in tehran  1103644\n",
      "1103645          remembering australian lives lost in 2017  1103645\n",
      "1103646  remount horsemanship helping veterans through ...  1103646\n",
      "1103647  roger federer rivals battling injury ahead aus...  1103647\n",
      "1103648  russian tankers fuelled north korea via transf...  1103648\n",
      "1103649  sa transport department defends major intersec...  1103649\n",
      "1103650  sea plane has crashed into the hawkesbury rive...  1103650\n",
      "1103651  search for survivors in hawkesbury sea plane c...  1103651\n",
      "1103652  second sexual assault reported at falls festiv...  1103652\n",
      "1103653  severe storms forecast for nye in south east q...  1103653\n",
      "1103654  snake catcher pleads for people not to kill re...  1103654\n",
      "1103655  south australia prepares for party to welcome ...  1103655\n",
      "1103656  strikers cool off the heat with big win in ade...  1103656\n",
      "1103657    stunning images from the sydney to hobart yacht  1103657\n",
      "1103658  the ashes smiths warners near miss liven up bo...  1103658\n",
      "1103659            timelapse: brisbanes new year fireworks  1103659\n",
      "1103660           what 2017 meant to the kids of australia  1103660\n",
      "1103661   what the papodopoulos meeting may mean for ausus  1103661\n",
      "1103662  who is george papadopoulos the former trump ca...  1103662\n",
      "\n",
      "[1103663 rows x 2 columns]\n",
      "1103663\n",
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "print(data_text)\n",
    "data_text['index']=data_text.index\n",
    "documents=data_text\n",
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/abhishek/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries for preprocessing\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-38-dc41ef993127>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-dc41ef993127>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    stemmer = SnowballStemmer(“english”)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = SnowballStemmer(“english”)\n",
    "    #This function is used so that we can use stemmer. Else error comes.\n",
    "    \n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain helps dampen bushfires\n",
      "original document: \n",
      "['rain', 'helps', 'dampen', 'bushfires']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['rain', 'help', 'dampen', 'bushfir']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "#Here we used boolean indexing and thus tried to take any random topic and then we used values attribute to get the values of the lsit returned.\n",
    "\n",
    "print(doc_sample)\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['decid', 'commun', 'broadcast', 'licenc']\n"
     ]
    }
   ],
   "source": [
    "#Applying to complete document, data preprocessing\n",
    "# For that, you can use, .map function but it works only with Series and not witrh DAtaframes.\n",
    "preprocessed_documents=documents['headline_text'].map(preprocess)\n",
    "preprocessed_documents[:5]\n",
    "print(preprocessed_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(18 unique tokens: ['broadcast', 'commun', 'decid', 'licenc', 'awar']...)\n",
      "broadcast\n",
      "commun\n",
      "decid\n",
      "licenc\n",
      "awar\n",
      "defam\n",
      "wit\n",
      "call\n",
      "infrastructur\n",
      "protect\n",
      "summit\n",
      "aust\n",
      "rise\n",
      "staff\n",
      "strike\n",
      "affect\n",
      "australian\n",
      "travel\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(preprocessed_documents[:5])\n",
    "print(dictionary)\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7f1552d7b240>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
